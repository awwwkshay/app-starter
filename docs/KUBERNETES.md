# ğŸ§­ Kubernetes Environments with Namespaces â€” Architecture & Best Practices

This document explains how to run **multiple environments (dev, staging, production)** inside a **single Kubernetes cluster** using **namespaces**, along with:

* Ingress routing per environment
* Automated TLS using **cert-manager + Let's Encrypt**
* URL convention per environment
* API vs Web routing (`/api` vs `/`)
* Why namespaces are useful

---

## ğŸ“Œ Why Multiple Environments in One Cluster?

You *can* run separate clusters (often used by larger enterprises), but for most teams:

âœ”ï¸ Cheaper
âœ”ï¸ Easier to manage
âœ”ï¸ Share compute resources
âœ”ï¸ Faster deployments
âœ”ï¸ Reduced ops overhead

Namespaces provide **logical isolation**, so each environment has its own:

| Resource        | Isolated by Namespace |
| --------------- | --------------------- |
| Deployments     | âœ”ï¸                    |
| Services        | âœ”ï¸                    |
| ConfigMaps      | âœ”ï¸                    |
| Secrets         | âœ”ï¸                    |
| RBAC Policies   | âœ”ï¸                    |
| Ingress Rules   | âœ”ï¸                    |
| Resource Quotas | âœ”ï¸                    |

---

## ğŸ·ï¸ Namespaces Design

We will use:

```
dev
staging
prod
```

---

### Create Namespaces

```sh
kubectl create namespace dev
kubectl create namespace staging
kubectl create namespace prod
```

---

## ğŸ” TLS + Certificate Automation (cert-manager)

Install cert-manager:

```sh
kubectl apply -f https://github.com/cert-manager/cert-manager/releases/latest/download/cert-manager.crds.yaml

helm repo add jetstack https://charts.jetstack.io
helm repo update

helm install cert-manager jetstack/cert-manager \
  --namespace cert-manager \
  --create-namespace \
  --version v1.15.0
```

---

### Configure Let's Encrypt ClusterIssuer

> Create once â€” usable by all namespaces.

```yaml
apiVersion: cert-manager.io/v1
kind: ClusterIssuer
metadata:
  name: letsencrypt-prod
spec:
  acme:
    email: you@example.com
    server: https://acme-v02.api.letsencrypt.org/directory
    privateKeySecretRef:
      name: letsencrypt-private-key
    solvers:
    - http01:
        ingress:
          class: nginx
```

Apply:

```sh
kubectl apply -f cluster-issuer.yaml
```

---

## ğŸŒ Domain Strategy

| Environment | URL Example         |
| ----------- | ------------------- |
| Dev         | `example.dev.com`   |
| Staging     | `example.stage.com` |
| Production  | `example.com`       |

---

## ğŸš¦ Ingress Architecture

Each namespace has its own ingress, example:

* `/` â†’ React frontend Service
* `/api` â†’ API backend Service

---

### Example Deployment Setup

ğŸ“ In each namespace you'll have:

```
deployment.yaml
service.yaml
ingress.yaml
```

---

### Example Ingress YAML for Each Namespace

#### `dev` namespace (`example.dev.com`)

```yaml
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: app-ingress
  namespace: dev
  annotations:
    kubernetes.io/ingress.class: "nginx"
    cert-manager.io/cluster-issuer: "letsencrypt-prod"
spec:
  tls:
  - hosts:
    - example.dev.com
    secretName: tls-example-dev
  rules:
  - host: example.dev.com
    http:
      paths:
      - path: /api
        pathType: Prefix
        backend:
          service:
            name: api-service
            port:
              number: 80
      - path: /
        pathType: Prefix
        backend:
          service:
            name: web-service
            port:
              number: 80
```

Repeat for staging and prod by changing namespace + host:

#### `staging` â†’ `example.stage.com`

#### `prod` â†’ `example.com`

> Only 3 fields change: Namespace, Host, TLS secret name.

---

## ğŸ” Sealed Secrets (Optional But Recommended)

Since you're managing multiple environments with real credentials, use:

```
bitnami-labs/sealed-secrets
```

This prevents storing raw secrets in Git.

---

## ğŸ§± RBAC + Quotas per Namespace

(Optional, recommended for teams):

Example Resource Quotas:

```yaml
apiVersion: v1
kind: ResourceQuota
metadata:
  name: compute-quota
  namespace: dev
spec:
  hard:
    requests.cpu: "2"
    requests.memory: 4Gi
    limits.cpu: "4"
    limits.memory: 8Gi
```

---

## ğŸš€ CI/CD Deployment Strategy

| Environment | Trigger                       | Source                      |
| ----------- | ----------------------------- | --------------------------- |
| Dev         | Every push / feature branch   | `:dev` or Git hash          |
| Staging     | PR merged â†’ Approval required | `:stage`                    |
| Production  | Manual or controlled deploy   | `:latest` or tagged release |

Use GitOps (ArgoCD / FluxCD) or Helm with environment values:

```
values.dev.yaml
values.staging.yaml
values.prod.yaml
```

---

## ğŸ§ª Testing URLs

| Environment | Frontend                     | API                             |
| ----------- | ---------------------------- | ------------------------------- |
| Dev         | `https://example.dev.com/`   | `https://example.dev.com/api`   |
| Staging     | `https://example.stage.com/` | `https://example.stage.com/api` |
| Prod        | `https://example.com/`       | `https://example.com/api`       |

---

## ğŸ Summary

| Feature                                 | Achieved |
| --------------------------------------- | -------- |
| Multiple environments in single cluster | âœ”ï¸       |
| Logical isolation using namespaces      | âœ”ï¸       |
| Automated HTTPS                         | âœ”ï¸       |
| Single ingress with routing rules       | âœ”ï¸       |
| Consistent domain naming                | âœ”ï¸       |
| Separate API+Web routing                | âœ”ï¸       |

---

## Next Step Suggestions

* Enable **Horizontal Pod Autoscaling**
* Add **monitoring (Prometheus + Grafana)**
* Add **logging (Loki, Elastic, or OpenSearch)**
* Add **backup strategies (Velero)**

---

If you want, I can also generate:

ğŸ“ `k8s/` folder structure
ğŸ§° Helm charts
ğŸš€ ArgoCD GitOps manifest
ğŸ“¦ Terraform scripts to bootstrap cluster

---
